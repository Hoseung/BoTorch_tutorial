{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [BoTorch with Ax](https://botorch.org/tutorials/custom_botorch_model_in_ax)\n",
    "\n",
    "> BoTorch makes no particular assumptions on what kind of model is being used, so long as is able to produce *samples from a posterior over outputs given an input x*.\n",
    "\n",
    "> BoTorch abstracts away from the particular form of the posterior by providing a simple Posterior API that **only requires** implementing an **rsample()** method for sampling from the posterior.\n",
    "\n",
    "\n",
    "## Simple gpytorch Exact GP Model\n",
    "... with RBF(+ARD) kernel to infer homoskedastic noise level\n",
    "\n",
    "[ARD:Automatic Relevance Determination](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ard.html)\n",
    "\n",
    "----\n",
    "\n",
    "### Radial Basis Function (RBF) kernel\n",
    "One of the most basic form of kernel that measures similarity between two.\n",
    "![RBF_eq](./RBF_eq.jpeg)\n",
    "its similarity to Gaussian distribution is one of the reason for its popularity. \n",
    "\n",
    "------\n",
    "\n",
    "####  [Gaussian MLE - derivation](http://jrmeyer.github.io/machinelearning/2017/08/18/mle.html)\n",
    "\n",
    "-----\n",
    "\n",
    "### Recommendation by GPyTorch\n",
    "\"If you don’t know what kernel to use, we recommend that you start out with a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel)`\"\n",
    "\n",
    "\n",
    "ConstantMean() is a safe bet as it converges to a constant as x -> infinity. In other words, the model will not make a dangerous guess where data points don't exist (near infinity). [Why mean of GP is uninteresting?](https://stats.stackexchange.com/questions/222238/why-is-the-mean-function-in-gaussian-process-uninteresting)\n",
    "\n",
    "* Alternate to ExactGP are Approximate GP and Deep GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import GammaPrior\n",
    "\n",
    "\n",
    "class SimplecCustomGP(ExactGP, GPyTorchModel):\n",
    "    \n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self, train_X, train_y):\n",
    "        super().__init__(train_X, train_y.squeeze(-1), GaussianLikelihood())\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(\n",
    "            base_kernel=RBFKernel(ard_num_dims=train_X.shape[-1])) \n",
    "        self.to(train_X) # make sure dtype and device are matched to train_X data.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".forward() is the method called during the (PyTorch) training loop to get the output, or the posterior. \n",
    "\n",
    "### Python NOTE: Method Resolutio Order (MRO)\n",
    "determines the order of inherited methods (in a multiple inheritance case)  \n",
    "Note that `__mro__()` method is only visible for a class, not for a class instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a factory function to be used with Ax's BotorchModel\n",
    "\n",
    "In Ax's `BoTorchModel`, different components of Bayesian optimization (model generation & fitting; acquisition function; optimizing model and acq. function)are exposed via functional API. \n",
    "\n",
    "A factory function can be passed to replace the default component.  \n",
    "\n",
    "The function MUST return a botorch `Model` object. What happens inside is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.fit import fit_gpytorch_model\n",
    "\n",
    "def _get_and_fit(Xs, Ys, **kwards):\n",
    "    \"\"\"\n",
    "    Return model\n",
    "    \"\"\"\n",
    "    model = SimplecCustomGP(Xs[0], Ys[0])\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a custom (non-GP) model, you need to build your own fitting loop.  \n",
    "(https://botorch.org/tutorials/fit_model_with_torch_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, Ax part\n",
    "\n",
    "We will optimize [Branin function](https://sites.google.com/site/gotestfunctions/multimodal-function-list/function-6-branin), which is a popular benchmark function for optimization techniques. i.e., has a quite complicated surface.\n",
    "![branin](branin_fn.png)\n",
    "\n",
    "Global optimum: f(xi) = 0.39788735772973816 for X = [-π , 12.275] or X = [π , 2.275] or [9.42478, 2.475]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def branin(param, *args):\n",
    "    x1, x2 = param[\"x1\"], param[\"x2\"]\n",
    "    y = (x2 - 5.1 / (4*np.pi**2) * x1**2 + 5 * x1 / np.pi -6)**2 + 10*(1- 1/(8*np.pi)) * np.cos(x1) + 10\n",
    "    # Add noise\n",
    "    y += random.normalvariate(0, 0.1) \n",
    "    return {\"branin\": (y, 0.0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import ParameterType, RangeParameter, SearchSpace\n",
    "\n",
    "search_space = SearchSpace(\n",
    "    parameters=[\n",
    "        RangeParameter(\n",
    "            name='x1', parameter_type=ParameterType.FLOAT, lower=-5, upper=10),\n",
    "        RangeParameter(\n",
    "            name='x2', parameter_type=ParameterType.FLOAT, lower=0, upper=15),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup an 'experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import SimpleExperiment\n",
    "\n",
    "exp = SimpleExperiment(\n",
    "    name='test_branin',\n",
    "    search_space=search_space,\n",
    "    evaluation_function=branin,\n",
    "    objective_name='branin',\n",
    "    minimize=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make up fake initial OBS.\n",
    "\n",
    "[Sobol generator](https://medium.com/@antoine_savine/sobol-sequence-explained-188f422b246b)\n",
    "![sobol](Sobol.png)\n",
    "left: random, right: Sobol — Modern Computational Finance (Antoine Savine, Wiley, 2018), page 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchTrial(experiment_name='test_branin', index=6, status=TrialStatus.CANDIDATE)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ax.modelbridge import get_sobol\n",
    "\n",
    "sobol = get_sobol(exp.search_space)\n",
    "exp.new_batch_trial(generator_run=sobol.gen(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Botorch model into the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization batch 1/5...\n",
      "Running optimization batch 2/5...\n",
      "Running optimization batch 3/5...\n",
      "Running optimization batch 4/5...\n",
      "Running optimization batch 5/5...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "from ax.modelbridge.factory import get_botorch\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Running optimization batch {i+1}/5...\")\n",
    "    model = get_botorch(\n",
    "        # exp carries information about search space and objective function.\n",
    "        experiment = exp, \n",
    "        data = exp.eval(),\n",
    "        search_space=exp.search_space,\n",
    "        model_constructor=_get_and_fit\n",
    "    )\n",
    "    batch = exp.new_trial(generator_run=model.gen(1))\n",
    "        \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
